{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('kh', 'tc'), ('qp', 'kh'), ('de', 'cg'), ('ka', 'co'), ('yn', 'aq'), ('qp', 'ub'), ('cg', 'tb'), ('vc', 'aq'), ('tb', 'ka'), ('wh', 'tc'), ('yn', 'cg'), ('kh', 'ub'), ('ta', 'co'), ('de', 'co'), ('tc', 'td'), ('tb', 'wq'), ('wh', 'td'), ('ta', 'ka'), ('td', 'qp'), ('aq', 'cg'), ('wq', 'ub'), ('ub', 'vc'), ('de', 'ta'), ('wq', 'aq'), ('wq', 'vc'), ('wh', 'yn'), ('ka', 'de'), ('kh', 'ta'), ('co', 'tc'), ('wh', 'qp'), ('tb', 'vc'), ('td', 'yn')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def load_data(option):\n",
    "    if option == 0:\n",
    "        with open('sample.txt') as f:\n",
    "            data = f.read().splitlines()\n",
    "    else:\n",
    "        with open('input.txt') as f:\n",
    "            data = f.read().splitlines()\n",
    "\n",
    "    arr = pd.DataFrame(data).to_numpy()\n",
    "    arr = [re.findall(r'(\\w+)-(\\w+)', row[0])[0] for row in arr]\n",
    "\n",
    "    return arr\n",
    "\n",
    "arr = load_data(0)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1194\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "arr = load_data(1)\n",
    "\n",
    "# Store connection in dictionary for fast access\n",
    "# Only count connection starting with 't'\n",
    "dict = {}\n",
    "for con in arr:\n",
    "    a, b = con\n",
    "    if a[0] == 't':\n",
    "        if a not in dict:\n",
    "            dict[a] = set([b])\n",
    "        else:\n",
    "            dict[a].add(b)\n",
    "    \n",
    "    if b[0] == 't':\n",
    "        if b not in dict:\n",
    "            dict[b] = set([a])\n",
    "        else:\n",
    "            dict[b].add(a)\n",
    "\n",
    "# Check for three inter-connected computers\n",
    "found_set = []\n",
    "for key, value in dict.items():\n",
    "    value = list(value)\n",
    "    for i in range(len(value)-1):\n",
    "        for j in range(i+1, len(value)):\n",
    "            if (value[i], value[j]) in arr or (value[j], value[i]) in arr:\n",
    "                found_set.append({key, value[i], value[j]})\n",
    "\n",
    "# Remove duplicates:\n",
    "count = len(found_set)\n",
    "for i in range(len(found_set)-1, -1, -1):\n",
    "    for j in range(i-1, -1, -1):\n",
    "        if len(found_set[i].intersection(found_set[j])) == 3:\n",
    "            count -= 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bd,bu,dv,gl,qc,rn,so,tm,wf,yl,ys,ze,zr\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "arr = load_data(1)\n",
    "\n",
    "# Store connection in dictionary for fast access\n",
    "dict = {}\n",
    "for con in arr:\n",
    "    a, b = con\n",
    "\n",
    "    if a not in dict:\n",
    "        dict[a] = set([b])\n",
    "    else:\n",
    "        dict[a].add(b)\n",
    "\n",
    "    if b not in dict:\n",
    "        dict[b] = set([a])\n",
    "    else:\n",
    "        dict[b].add(a)\n",
    "\n",
    "# For each node, check the largest possible set and store all connections\n",
    "largest_set = set([])\n",
    "for key, values in dict.items():\n",
    "    # Establish the connectivity dir\n",
    "    # The count reflect the number of neighbors (excluding self)\n",
    "    connectivity_dir = {}\n",
    "    for value in values:\n",
    "        connectivity_dir[value] = 1\n",
    "    \n",
    "    # Calculate the connectivity (basically a 2-step BFS from key)\n",
    "    for other_key in values:\n",
    "        for value in dict[other_key]:\n",
    "            if value != key:\n",
    "                if value not in connectivity_dir:\n",
    "                    connectivity_dir[value] = 1\n",
    "                else:\n",
    "                    connectivity_dir[value] += 1\n",
    "\n",
    "    # Flip the directory (so that it becomes count: members)\n",
    "    set_dir = {}\n",
    "    for other_key, value in connectivity_dir.items():\n",
    "        if value not in set_dir:\n",
    "            set_dir[value] = set([other_key])\n",
    "        else:\n",
    "            set_dir[value].add(other_key)\n",
    "\n",
    "    # Does the largest count (except for self) higher than the current best set?\n",
    "    max_count = max(set_dir.keys())\n",
    "    if max_count <= len(largest_set):\n",
    "        continue\n",
    "\n",
    "    # Does the largest set makes sense (there could be more than one largest set from self)\n",
    "    if len(set_dir[max_count]) != max_count:\n",
    "        continue\n",
    "\n",
    "    # We found a new max set, save it\n",
    "    largest_set = set_dir[max_count]\n",
    "    largest_set.add(key)\n",
    "\n",
    "# Once the largest set is found, sort them\n",
    "sorted_set = sorted(largest_set)\n",
    "print(','.join(sorted_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
